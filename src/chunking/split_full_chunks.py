import re
from rapidfuzz import fuzz, process
import os
import json

def sentence_split(text):
    """ä¸­è‹±æ–‡é€šç”¨çš„åˆ†å¥"""
    # ä¿ç•™ä¸­è‹±æ–‡æ ‡ç‚¹ä½œä¸ºå¥å­åˆ†éš”ç¬¦
    sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ.!?])\s*', text.strip())
    return [s for s in sentences if s]

def find_best_match(sentence_list, target, threshold=70):
    """
    åœ¨å¥å­åˆ—è¡¨ä¸­æ‰¾åˆ°ä¸ target æœ€ç›¸ä¼¼çš„å¥å­ç´¢å¼•
    ä½¿ç”¨ partial_ratioï¼Œæé«˜é²æ£’æ€§
    """
    best_idx, best_score = -1, 0
    for i, sent in enumerate(sentence_list):
        score = fuzz.partial_ratio(sent.lower(), target.lower())
        if score > best_score:
            best_score, best_idx = score, i
    return best_idx if best_score >= threshold else -1

def split_text_by_borders_aligned(text, borders, threshold=60):
    """
    æ ¹æ® borders åˆ‡åˆ†æ–‡æœ¬ï¼Œä½†ä¿è¯åˆ‡åˆ†ç‚¹è½åœ¨æ ‡ç‚¹ç¬¦å·åé¢ï¼ˆé¿å…æˆªæ–­å¥å­/å•è¯ï¼‰
    """
    cut_positions = []
    lower_text = text.lower()

    for border in borders:
        start_candidate = border[0].lower()
        # åœ¨åŸæ–‡ä¸­æ‰¾ä½ç½®
        match_pos = lower_text.find(start_candidate)
        if match_pos == -1:
            # fallback: ç”¨ rapidfuzz æ‰¾
            match, score, pos = process.extractOne(
                start_candidate,
                [lower_text[i:i+len(start_candidate)+50] for i in range(len(lower_text)-len(start_candidate))],
                scorer=fuzz.partial_ratio
            )
            if score >= threshold:
                match_pos = pos
            else:
                print(f"[WARN] Border not matched: {border[0][:30]}...")
                continue

        # ğŸš© å‘å‰æ‰¾æœ€è¿‘çš„æ ‡ç‚¹ç¬¦å·ï¼Œé¿å…åˆ‡åœ¨å•è¯ä¸­é—´
        punctuation = "ã€‚ï¼ï¼Ÿ.!?"
        while match_pos > 0 and text[match_pos] not in punctuation:
            match_pos -= 1
        if match_pos > 0:
            cut_positions.append(match_pos + 1)  # åˆ‡åœ¨æ ‡ç‚¹ä¹‹å

    # æ’åºï¼Œå»é‡
    cut_positions = sorted(set(cut_positions))

    # æŒ‰ä½ç½®åˆ‡åˆ†
    chunks = []
    prev = 0
    for pos in cut_positions:
        chunk_text = text[prev:pos].strip()
        if chunk_text:
            chunks.append({"text": chunk_text})
        prev = pos
    # æœ€åä¸€æ®µ
    if prev < len(text):
        chunks.append({"text": text[prev:].strip()})

    # ä¸€è‡´æ€§æ£€æŸ¥
    expected = len(borders) + 1
    if len(chunks) != expected:
        print(f"[WARN] Expected {expected} chunks, got {len(chunks)}")

    return chunks


def main():
    base_chunking_dir = "./datasets/finevideo/chunking"
    base_metadata_dir = "./datasets/finevideo/metadata"

    index_file = os.path.join(base_chunking_dir, "border_no_chunk_border_ge3.json")

    with open(index_file, "r", encoding="utf-8") as f:
        index_data = json.load(f)

    for category, file_list in index_data.items():
        for file_path in file_list:
            with open(file_path, "r", encoding="utf-8") as f:
                sample = json.load(f)

            if "borders" not in sample:
                continue

            borders = sample["borders"]

            # ä» metadata è¯»å–åŸå§‹æ–‡æœ¬
            filename = os.path.basename(file_path)  # e.g. sample_160.json
            meta_path = os.path.join(base_metadata_dir, category, filename)

            if not os.path.exists(meta_path):
                print(f"[WARN] Metadata file not found: {meta_path}")
                continue

            with open(meta_path, "r", encoding="utf-8") as f:
                meta = json.load(f)

            text = meta.get("text_to_speech", "").strip()
            if not text:
                print(f"[WARN] Empty text_to_speech in {meta_path}")
                continue

            chunks = split_text_by_borders_aligned(text, borders)

            # âš¡ åˆ é™¤æ—§çš„ chunksï¼Œå†™å…¥æ–°çš„
            if "chunks" in sample:
                del sample["chunks"]
            sample["chunks"] = chunks

            # å†™å›åŸæ–‡ä»¶
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(sample, f, ensure_ascii=False, indent=2)

            print(f"[OK] Processed {file_path} â†’ {len(chunks)} chunks")


if __name__ == "__main__":
    main()
